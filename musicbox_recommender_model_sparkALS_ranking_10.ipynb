{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.4.0\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.7.1 (default, Dec 14 2018 13:28:58)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "exec(open(os.path.join(os.environ[\"SPARK_HOME\"], \"python/pyspark/shell.py\")).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Bucketizer, MinMaxScaler, VectorAssembler\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml import Transformer\n",
    "from pyspark.sql import Window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this file contains 'uid', 'song_id' and freqency features for implicity rating\n",
    "\n",
    "df = spark.read.csv(\"/Users/fanyang/Documents/musicbox/data/recommender_model01_0116.csv\",\n",
    "                   header=True, inferSchema=True).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>uid</th>\n",
       "      <th>song_id</th>\n",
       "      <th>comp_play_last_7</th>\n",
       "      <th>comp_play_last_14</th>\n",
       "      <th>comp_play_last_21</th>\n",
       "      <th>comp_play_last_30</th>\n",
       "      <th>comp_play_last_44</th>\n",
       "      <th>freq_P_last_7</th>\n",
       "      <th>freq_P_last_14</th>\n",
       "      <th>freq_P_last_21</th>\n",
       "      <th>freq_P_last_30</th>\n",
       "      <th>freq_P_last_44</th>\n",
       "      <th>freq_D_last_7</th>\n",
       "      <th>freq_D_last_14</th>\n",
       "      <th>freq_D_last_21</th>\n",
       "      <th>freq_D_last_30</th>\n",
       "      <th>freq_D_last_44</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>103103073</td>\n",
       "      <td>572912</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>104737814</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10919480</td>\n",
       "      <td>277650</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10919480</td>\n",
       "      <td>389413</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10919480</td>\n",
       "      <td>461313</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _c0        uid song_id  comp_play_last_7  comp_play_last_14  \\\n",
       "0    0  103103073  572912                 0                  0   \n",
       "1    1  104737814       0                 0                  0   \n",
       "2    2   10919480  277650                 2                  2   \n",
       "3    3   10919480  389413                 0                  0   \n",
       "4    4   10919480  461313                 1                  2   \n",
       "\n",
       "   comp_play_last_21  comp_play_last_30  comp_play_last_44  freq_P_last_7  \\\n",
       "0                  0                  0                  0              0   \n",
       "1                  0                  0                  0              0   \n",
       "2                  2                  2                  3              2   \n",
       "3                  0                  1                  1              0   \n",
       "4                  2                  2                  2              1   \n",
       "\n",
       "   freq_P_last_14  freq_P_last_21  freq_P_last_30  freq_P_last_44  \\\n",
       "0               0               0               0               1   \n",
       "1               0               0               0             127   \n",
       "2               2               2               2               3   \n",
       "3               0               0               1               1   \n",
       "4               2               2               3               6   \n",
       "\n",
       "   freq_D_last_7  freq_D_last_14  freq_D_last_21  freq_D_last_30  \\\n",
       "0              0               0               0               0   \n",
       "1              0               0               0               0   \n",
       "2              0               0               0               0   \n",
       "3              0               0               0               0   \n",
       "4              0               0               0               0   \n",
       "\n",
       "   freq_D_last_44  \n",
       "0               0  \n",
       "1               0  \n",
       "2               1  \n",
       "3               0  \n",
       "4               1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df.take(5), columns=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. data validation (remove inactive uid/song_id, invalid frequency features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before data cleaning, original shape of dataframe is: \n",
      "2005120 18\n"
     ]
    }
   ],
   "source": [
    "print(\"Before data cleaning, original shape of dataframe is: \")\n",
    "print(df.count(), len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------------+\n",
      "|count(DISTINCT uid)|count(DISTINCT song_id)|\n",
      "+-------------------+-----------------------+\n",
      "|              56065|                 311180|\n",
      "+-------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg(F.countDistinct('uid'), F.countDistinct('song_id')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data \n",
    "df = df.drop('_c0')\n",
    "df = df[df.song_id != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|      uid|count|\n",
      "+---------+-----+\n",
      "|169031835| 2223|\n",
      "|168451768| 1503|\n",
      "|168139162| 1448|\n",
      "|168954949| 1425|\n",
      "|168479098| 1404|\n",
      "|167587977| 1327|\n",
      "|168255392| 1324|\n",
      "|168636306| 1318|\n",
      "|168393361| 1250|\n",
      "|168156556| 1248|\n",
      "+---------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find the most active uid\n",
    "df_user_select = df.groupBy('uid').count().orderBy(F.col('count'), ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|      uid|count|\n",
      "+---------+-----+\n",
      "|167723216|    1|\n",
      "|168437519|    1|\n",
      "|168612160|    1|\n",
      "|168680386|    1|\n",
      "|169030108|    1|\n",
      "|168670275|    1|\n",
      "|167903161|    1|\n",
      "|167644114|    1|\n",
      "|168730743|    1|\n",
      "|168746784|    1|\n",
      "+---------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find the least active uid\n",
    "df_user_select = df.groupBy('uid').count().orderBy(F.col('count')).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "| song_id|count|\n",
      "+--------+-----+\n",
      "|15249349| 9267|\n",
      "| 9950164| 8729|\n",
      "| 6468891| 5570|\n",
      "| 5237384| 5343|\n",
      "| 3287564| 4799|\n",
      "|15807836| 4471|\n",
      "| 5114569| 4230|\n",
      "| 6657692| 3928|\n",
      "| 3620537| 3599|\n",
      "| 7149583| 3255|\n",
      "+--------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find the most popular song_id\n",
    "df_song_select = df.groupBy('song_id').count().orderBy(F.col('count'), ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "| song_id|count|\n",
      "+--------+-----+\n",
      "|  123146|    1|\n",
      "| 6188853|    1|\n",
      "|19374223|    1|\n",
      "| 3577158|    1|\n",
      "| 1106674|    1|\n",
      "| 3230157|    1|\n",
      "| 2834769|    1|\n",
      "| 4307451|    1|\n",
      "| 4119915|    1|\n",
      "|13438469|    1|\n",
      "+--------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find the least popular song_id\n",
    "df_song_select = df.groupBy('song_id').count().orderBy(F.col('count')).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove most inactive uid\n",
    "df_user_select = df.groupBy('uid').count().where(F.col('count')>10)\n",
    "df = df_user_select.join(df, on=['uid'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove most inactive song_id\n",
    "df_song_select = df.groupBy('song_id').count().where(F.col('count')>10)\n",
    "df = df_song_select.join(df, on=['song_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------------+\n",
      "|count(DISTINCT uid)|count(DISTINCT song_id)|\n",
      "+-------------------+-----------------------+\n",
      "|              30137|                  24144|\n",
      "+-------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg(F.countDistinct('uid'), F.countDistinct('song_id')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing inactive uid and song_id, the current shape of dataframe is: \n",
      "1359307 19\n"
     ]
    }
   ],
   "source": [
    "print(\"After removing inactive uid and song_id, the current shape of dataframe is: \")\n",
    "print(df.count(), len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. generate implicit rating from frequency feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 1: select features from longest time frame 44 days for implicit rating\n",
    "# remove rows that the selected feature contain zero\n",
    "\n",
    "df_feature_select = df.select('uid', 'song_id','comp_play_last_44', 'freq_P_last_44', 'freq_D_last_44') \\\n",
    ".where(((F.col('comp_play_last_44')!=0)|(F.col('freq_P_last_44')!=0)) & (F.col('freq_D_last_44')!=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----------------+--------------+--------------+\n",
      "|uid|song_id|comp_play_last_44|freq_P_last_44|freq_D_last_44|\n",
      "+---+-------+-----------------+--------------+--------------+\n",
      "|  0|      0|                0|             0|             0|\n",
      "+---+-------+-----------------+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check NULL before feature transformation\n",
    "\n",
    "df_feature_select.select(*[F.sum(F.col(c).isNull().cast('int')) \\\n",
    "                           .alias(c) for c in df_feature_select.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform features(take log10, and then combine the three features into one)\n",
    "# implicit rating: assuming 'comp_play_last_44', 'freq_P_last_44', 'freq_D_last_44'  Equally contribute to rating\n",
    "\n",
    "df_feature_transform = df_feature_select.withColumn('comp_play_last_44_transf', F.log10(F.col('comp_play_last_44')+1)) \\\n",
    "                        .withColumn('freq_P_last_44_transf', F.log10(F.col('freq_P_last_44')+1)) \\\n",
    "                        .withColumn('freq_D_last_44_transf', F.log10(F.col('freq_D_last_44')+1)) \\\n",
    "                        .withColumn('rating', 0.33*F.col('comp_play_last_44_transf')+0.33*F.col('freq_P_last_44_transf')\\\n",
    "                            +0.33*F.col('freq_D_last_44_transf')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforma and standardrize rating \n",
    "# VectorAssembler is a transformer that combines a given list of columns into a single vector column\n",
    "\n",
    "\n",
    "assembler = VectorAssembler(inputCols=['rating'], outputCol='rating_assembled')\n",
    "scaler = MinMaxScaler(inputCol='rating_assembled', outputCol='rating_scaled')\n",
    "pp = Pipeline(stages=[assembler, scaler])\n",
    "pp_model = pp.fit(df_feature_transform)\n",
    "df_final = pp_model.transform(df_feature_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[uid: int, song_id: decimal(20,0), comp_play_last_44: int, freq_P_last_44: int, freq_D_last_44: int, comp_play_last_44_transf: double, freq_P_last_44_transf: double, freq_D_last_44_transf: double, rating: double, rating_assembled: vector, rating_scaled: vector]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# udf User defined function\n",
    "Vec2num_udf = F.udf(lambda x: float(x[0]), DoubleType())\n",
    "df_final = df_final.withColumn('rating_scaled_num', Vec2num_udf('rating_scaled'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[uid: int, song_id: decimal(20,0), comp_play_last_44: int, freq_P_last_44: int, freq_D_last_44: int, comp_play_last_44_transf: double, freq_P_last_44_transf: double, freq_D_last_44_transf: double, rating: double, rating_assembled: vector, rating_scaled: vector, rating_scaled_num: double]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucketizer transforms a column of continuous features to a column of feature buckets\n",
    "# put scaled_rating into 5 bins\n",
    "\n",
    "splits = [.0, 1/30, 1/15, 5/15, 7/15, 1]\n",
    "bucketizer = Bucketizer(splits=splits, inputCol='rating_scaled_num', outputCol='implicit_ratings')\n",
    "df_final = bucketizer.transform(df_final)\n",
    "df_final = df_final.withColumn('implicit_ratings', F.col('implicit_ratings')+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[uid: int, song_id: decimal(20,0), comp_play_last_44: int, freq_P_last_44: int, freq_D_last_44: int, comp_play_last_44_transf: double, freq_P_last_44_transf: double, freq_D_last_44_transf: double, rating: double, rating_assembled: vector, rating_scaled: vector, rating_scaled_num: double, implicit_ratings: double]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_model = df_final.select('uid', 'song_id', 'implicit_ratings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- uid: integer (nullable = true)\n",
      " |-- song_id: decimal(20,0) (nullable = true)\n",
      " |-- implicit_ratings: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final_model.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+\n",
      "|implicit_ratings| count|\n",
      "+----------------+------+\n",
      "|             1.0| 21681|\n",
      "|             4.0| 16371|\n",
      "|             3.0|120856|\n",
      "|             2.0| 23822|\n",
      "|             5.0|  3759|\n",
      "+----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final_model.groupBy('implicit_ratings').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. build recommendation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomSplitByUID(df, weights, seed=None):\n",
    "    trainingRation = weights[0]\n",
    "    fractions = {row['uid']: trainingRation for row in df.select('uid').distinct().collect()}\n",
    "    training = df.sampleBy('uid', fractions, seed)\n",
    "    testRDD = df.rdd.subtract(training.rdd)\n",
    "    test = spark.createDataFrame(testRDD, df.schema)\n",
    "    return training, test\n",
    "\n",
    "train, test = randomSplitByUID(df_final_model, weights=[0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implicitPrefs: specifies whether to use the explicit rating (defaults to false, the explicit rating).\n",
    "# rank: the number of latent factors in the model (defaults to 10).\n",
    "# maxIter: maximum number of iterations to run (defaults to 10).\n",
    "# regParam: specifies the regularization parameter in ALS (defaults to 1.0)\n",
    "# alpha: a parameter for ALS implicit rating governing baseline confidence (defaults to 1.0).\n",
    "\n",
    "# model_1\n",
    "\n",
    "als = ALS(implicitPrefs=True, seed=42,userCol=\"uid\", itemCol=\"song_id\", ratingCol=\"implicit_ratings\") \\\n",
    "    .setRank(50) \\\n",
    "    .setMaxIter(22) \\\n",
    "    .setRegParam(0.5) \\\n",
    "    .setAlpha(40)\n",
    "\n",
    "model = als.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+----------------+------------+\n",
      "|      uid|song_id|implicit_ratings|  prediction|\n",
      "+---------+-------+----------------+------------+\n",
      "|168497431| 118989|             2.0|   0.5367587|\n",
      "|168966848| 118989|             2.0|   0.8157581|\n",
      "|168398182| 118989|             2.0|  0.68088716|\n",
      "|168794096| 118989|             3.0|   0.1478242|\n",
      "|168666973| 133948|             3.0|  -0.3624314|\n",
      "|168761984| 167532|             1.0|         NaN|\n",
      "| 74921309| 200878|             4.0| 0.061903685|\n",
      "|168053065| 235318|             3.0|  0.21362168|\n",
      "|167637737| 235318|             4.0|-0.056609396|\n",
      "|167963231| 255362|             1.0|   1.0998604|\n",
      "+---------+-------+----------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recommendations = model.transform(test)\n",
    "recommendations.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+----------------+------------+\n",
      "|      uid|song_id|implicit_ratings|  prediction|\n",
      "+---------+-------+----------------+------------+\n",
      "|168497431| 118989|             2.0|   0.5367587|\n",
      "|168966848| 118989|             2.0|   0.8157581|\n",
      "|168398182| 118989|             2.0|  0.68088716|\n",
      "|168794096| 118989|             3.0|   0.1478242|\n",
      "|168666973| 133948|             3.0|  -0.3624314|\n",
      "|168761984| 167532|             1.0|         NaN|\n",
      "| 74921309| 200878|             4.0| 0.061903685|\n",
      "|168053065| 235318|             3.0|  0.21362168|\n",
      "|167637737| 235318|             4.0|-0.056609396|\n",
      "|167963231| 255362|             1.0|   1.0998604|\n",
      "+---------+-------+----------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recommendations.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|      uid|             song_id|\n",
      "+---------+--------------------+\n",
      "|167582087|[3247615, 6203964...|\n",
      "|167627297|  [6212893, 6660691]|\n",
      "|167674030|[96891, 6771014, ...|\n",
      "|167683346|[6196652, 3973161...|\n",
      "|167697454|[850803, 3223114,...|\n",
      "|167727745|           [9918220]|\n",
      "|167735352|            [516330]|\n",
      "|167746855|  [4849640, 5390879]|\n",
      "|167760432|[1128081, 507941,...|\n",
      "|167888996|[1149606, 908531,...|\n",
      "|167894223|[3565454, 7116549...|\n",
      "|167910793| [6435339, 24013319]|\n",
      "|167913407|[6651583, 4982519...|\n",
      "|167979490|  [6159657, 4152712]|\n",
      "|167993496|           [7187500]|\n",
      "|168045751|           [6700790]|\n",
      "|168054336|[157606, 1041659,...|\n",
      "|168150258|            [328037]|\n",
      "|168236162|[874711, 1166670,...|\n",
      "|168275526|[6686279, 708518,...|\n",
      "+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make recommendation for each uid\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "windowSpec = Window.partitionBy('uid').orderBy(col('prediction').desc())\n",
    "predicted_recommendation = recommendations \\\n",
    "            .select('uid', 'song_id', 'prediction', F.rank().over(windowSpec).alias('rank')) \\\n",
    "            .where('rank <= {0}'.format(10)) \\\n",
    "            .groupBy('uid') \\\n",
    "            .agg(expr('collect_list(song_id) as song_id'))\n",
    "\n",
    "predicted_recommendation.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|      uid|             song_id|\n",
      "+---------+--------------------+\n",
      "|167582087|[3247615, 6203964...|\n",
      "|167627297|  [6212893, 6660691]|\n",
      "|167674030|[96891, 6771014, ...|\n",
      "|167683346|[6196652, 3973161...|\n",
      "|167697454|[850803, 3223114,...|\n",
      "|167727745|           [9918220]|\n",
      "|167735352|            [516330]|\n",
      "|167746855|  [4849640, 5390879]|\n",
      "|167760432|[1128081, 507941,...|\n",
      "|167888996|[1149606, 908531,...|\n",
      "+---------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_recommendation.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|      uid|             song_id|\n",
      "+---------+--------------------+\n",
      "|167582087|[1102831, 868744,...|\n",
      "|167627297|  [6212893, 6660691]|\n",
      "|167674030|[7186052, 2365697...|\n",
      "|167683346|[3973161, 6357412...|\n",
      "|167697454|[1928478, 590383,...|\n",
      "|167727745|           [9918220]|\n",
      "|167735352|            [516330]|\n",
      "|167746855|  [4849640, 5390879]|\n",
      "|167760432|[94232, 978692, 1...|\n",
      "|167888996|[1149606, 908531,...|\n",
      "+---------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# list actual recommendations based on uid's implicit ratings\n",
    "\n",
    "windowSpec = Window.partitionBy('uid').orderBy(col('implicit_ratings').desc())\n",
    "rated_recommendation = recommendations \\\n",
    "            .select('uid', 'song_id', 'implicit_ratings', F.rank().over(windowSpec).alias('rank')) \\\n",
    "            .where('rank <= {0}'.format(30)) \\\n",
    "            .groupBy('uid') \\\n",
    "            .agg(expr('collect_list(song_id) as song_id'))\n",
    "\n",
    "rated_recommendation.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|      uid|             song_id|\n",
      "+---------+--------------------+\n",
      "|167582087|[1102831, 868744,...|\n",
      "|167627297|  [6212893, 6660691]|\n",
      "|167674030|[7186052, 2365697...|\n",
      "|167683346|[3973161, 6357412...|\n",
      "|167697454|[1928478, 590383,...|\n",
      "|167727745|           [9918220]|\n",
      "|167735352|            [516330]|\n",
      "|167746855|  [4849640, 5390879]|\n",
      "|167760432|[94232, 978692, 1...|\n",
      "|167888996|[1149606, 908531,...|\n",
      "|167894223|[3565454, 7024394...|\n",
      "|167910793| [24013319, 6435339]|\n",
      "|167913407|[7051854, 4982519...|\n",
      "|167979490|  [6159657, 4152712]|\n",
      "|167993496|           [7187500]|\n",
      "|168045751|           [6700790]|\n",
      "|168054336|[3401253, 86762, ...|\n",
      "|168150258|            [328037]|\n",
      "|168236162|[955482, 6412113,...|\n",
      "|168275526|[708528, 4441094,...|\n",
      "+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rated_recommendation.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use ranking for model evaluation\n",
    "\n",
    "recommendaton_evaluation = predicted_recommendation.join(F.broadcast(rated_recommendation), 'uid', 'inner') \\\n",
    "            .rdd \\\n",
    "            .map(lambda row: (row[1], row[2]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation of model_1: \n",
      "metric:  0.9684\n",
      "meanAveragePrecision:  0.9551\n",
      "precisionAt:  0.1336\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import RankingMetrics\n",
    "\n",
    "rankingMetrics = RankingMetrics(recommendaton_evaluation)\n",
    "metric = rankingMetrics.ndcgAt(30)\n",
    "\n",
    "print('evaluation of model_1: ')\n",
    "print('metric: ', '%.4f' %metric)\n",
    "print('meanAveragePrecision: ', '%.4f' %rankingMetrics.meanAveragePrecision)\n",
    "print('precisionAt: ', '%.4f'% rankingMetrics.precisionAt(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. tune parameter of recommendation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/apache-spark/2.4.0/libexec/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1159, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/apache-spark/2.4.0/libexec/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/local/Cellar/apache-spark/2.4.0/libexec/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1164, in send_command\n",
      "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
      "py4j.protocol.Py4JNetworkError: Error while receiving\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "org does not exist in the JVM",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-949c1f50fb3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# alpha: a parameter for ALS implicit rating governing baseline confidence (defaults to 1.0).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mALS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimplicitPrefs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muserCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"uid\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitemCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"song_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratingCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"implicit_ratings\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0msetRank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0msetMaxIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.0/libexec/python/pyspark/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Method %s forces keyword arguments.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.0/libexec/python/pyspark/ml/recommendation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, rank, maxIter, regParam, numUserBlocks, numItemBlocks, implicitPrefs, alpha, userCol, itemCol, seed, ratingCol, nonnegative, checkpointInterval, intermediateStorageLevel, finalStorageLevel, coldStartStrategy)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[1;32m    166\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mALS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_java_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"org.apache.spark.ml.recommendation.ALS\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         self._setDefault(rank=10, maxIter=10, regParam=0.1, numUserBlocks=10, numItemBlocks=10,\n\u001b[1;32m    169\u001b[0m                          \u001b[0mimplicitPrefs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitemCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"item\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.0/libexec/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_new_java_obj\u001b[0;34m(java_class, *args)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mjava_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_jvm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjava_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mjava_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mjava_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_py2java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjava_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mjava_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.0/libexec/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1657\u001b[0m             message = compute_exception_message(\n\u001b[1;32m   1658\u001b[0m                 \"{0} does not exist in the JVM\".format(name), error_message)\n\u001b[0;32m-> 1659\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPy4JError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JError\u001b[0m: org does not exist in the JVM"
     ]
    }
   ],
   "source": [
    "# implicitPrefs: specifies whether to use the explicit rating (defaults to false, the explicit rating).\n",
    "# rank: the number of latent factors in the model (defaults to 10).\n",
    "# maxIter: maximum number of iterations to run (defaults to 10).\n",
    "# regParam: specifies the regularization parameter in ALS (defaults to 1.0)\n",
    "# alpha: a parameter for ALS implicit rating governing baseline confidence (defaults to 1.0).\n",
    "\n",
    "als = ALS(implicitPrefs=True, seed=42,userCol=\"uid\", itemCol=\"song_id\", ratingCol=\"implicit_ratings\") \\\n",
    "    .setRank(100) \\\n",
    "    .setMaxIter(40) \\\n",
    "    .setRegParam(0.1) \\\n",
    "    .setAlpha(1)\n",
    "\n",
    "model = als.fit(train)\n",
    "recommendations = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowSpec = Window.partitionBy('uid').orderBy(col('prediction').desc())\n",
    "predicted_recommendation = recommendations \\\n",
    "            .select('uid', 'song_id', 'prediction', F.rank().over(windowSpec).alias('rank')) \\\n",
    "            .where('rank <= {0}'.format(10)) \\\n",
    "            .groupBy('uid') \\\n",
    "            .agg(expr('collect_list(song_id) as song_id'))\n",
    "\n",
    "\n",
    "\n",
    "windowSpec = Window.partitionBy('uid').orderBy(col('implicit_ratings').desc())\n",
    "rated_recommendation = recommendations \\\n",
    "            .select('uid', 'song_id', 'implicit_ratings', F.rank().over(windowSpec).alias('rank')) \\\n",
    "            .where('rank <= {0}'.format(30)) \\\n",
    "            .groupBy('uid') \\\n",
    "            .agg(expr('collect_list(song_id) as song_id'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception happened during processing of request from ('127.0.0.1', 53474)\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.7/socketserver.py\", line 313, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/anaconda3/lib/python3.7/socketserver.py\", line 344, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/anaconda3/lib/python3.7/socketserver.py\", line 357, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/anaconda3/lib/python3.7/socketserver.py\", line 717, in __init__\n",
      "    self.handle()\n",
      "  File \"/usr/local/Cellar/apache-spark/2.4.0/libexec/python/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/usr/local/Cellar/apache-spark/2.4.0/libexec/python/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/usr/local/Cellar/apache-spark/2.4.0/libexec/python/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/usr/local/Cellar/apache-spark/2.4.0/libexec/python/pyspark/serializers.py\", line 714, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "recommendaton_evaluation = predicted_recommendation.join(F.broadcast(rated_recommendation), 'uid', 'inner') \\\n",
    "            .rdd \\\n",
    "            .map(lambda row: (row[1], row[2]))  \n",
    "\n",
    "\n",
    "rankingMetrics = RankingMetrics(recommendaton_evaluation)\n",
    "metric = rankingMetrics.ndcgAt(30)\n",
    "print('evaluation of model_2: ')\n",
    "print('metric: ', '%.4f' %metric)\n",
    "print('meanAveragePrecision: ', '%.4f' %rankingMetrics.meanAveragePrecision)\n",
    "print('precisionAt: ', '%.4f'% rankingMetrics.precisionAt(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
